
using ThreadPinning
import NUMA

@testset "Blocking" begin

@testset "BlockGrid" begin
    @testset "$(join(N, 'Ã—')) - $(join(block_size, 'Ã—')) - $nghost" for (N, block_size, nghost) in (
            ((100, 100), ( 32,  32), 4),  # Normal mix of static and edge blocks
            ((100, 100), ( 16,  48), 4),  # Uneven mix of static and edge blocks
            ((100, 100), ( 57,  57), 4),  # Edge blocks too small, merged with closest static blocks
            ((100, 100), ( 64,  57), 4),  # Same but uneven
            ((100, 100), (106, 106), 4),  # Edge blocks too small, merged with closest static blocks (only edge blocks left)
            ((100, 100), (108, 108), 4),  # Perfect match: only a single static block
            ((100, 100), (  0,   0), 4),  # No blocking, only edge blocks
            ((100,  50), ( 64,  64), 4),  # Static size along X, edge size along Y
            ((240, 240), ( 64,  32), 4),  # Bigger test case with uneven block size
        )
        ref_params = get_reference_params(:Sod, Float64; N, block_size, nghost)
        grid = Armon.BlockGrid(ref_params)

        @testset "Grid" begin
            if prod(block_size) > 0
                @test prod(grid.grid_size) == length(grid.blocks) + length(grid.edge_blocks)
                grid_size, static_grid, remainder_size = Armon.grid_dimensions(ref_params)
                @test all(remainder_size .> nghost .|| remainder_size .== 0)
            else
                @test isempty(grid.blocks)
                @test !isempty(grid.edge_blocks)
                @test prod(grid.grid_size) == length(grid.edge_blocks)
            end

            @test Armon.device_array_type(grid) == Armon.host_array_type(grid) == Armon.buffer_array_type(grid) == Vector{Float64}
            @test Armon.device_is_host(grid)
            @test Armon.buffers_on_device(grid)
            @test Armon.ghosts(grid) == nghost
            @test Armon.static_block_size(grid) == block_size
        end

        @testset "Domain" begin
            real_cell_count = 0
            all_cell_count = 0
            blk_bytes = 0
            for blk in Armon.all_blocks(grid)
                real_cell_count += prod(Armon.real_block_size(blk.size))
                all_cell_count  += prod(Armon.block_size(blk.size))
                blk_bytes += sizeof(blk)
            end

            @test real_cell_count == prod(N)
            if prod(grid.grid_size) == 1
                @test all_cell_count  == prod(N .+ 2*ref_params.nghost)
            end

            total_mem = all_cell_count * sizeof(Float64) * length(Armon.block_vars())
            remote_blocks_overhead = sum(sizeof.(grid.remote_blocks))
            device_memory, host_memory = Armon.memory_required(ref_params)
            @test total_mem == device_memory
            @test host_memory == total_mem + blk_bytes + remote_blocks_overhead
        end

        @testset "Neighbours" begin
            for blk in Iterators.flatten((grid.blocks, grid.edge_blocks, grid.remote_blocks))
                if blk isa Armon.RemoteTaskBlock
                    if blk.neighbour isa Armon.RemoteTaskBlock
                        @test blk.neighbour.neighbour == blk
                    else
                        opposite_side = Armon.side_from_offset(Tuple(blk.pos) .- Tuple(blk.neighbour.pos))
                        @test blk.neighbour.neighbours[Int(opposite_side)] == blk
                    end
                else
                    for (side, neighbour) in zip(instances(Armon.Side.T), blk.neighbours)
                        if neighbour isa Armon.RemoteTaskBlock
                            @test neighbour.neighbour == blk
                        else 
                            opposite_side = Armon.opposite_of(side)
                            @test neighbour.neighbours[Int(opposite_side)] == blk
                        end
                    end
                end
            end
        end

        @testset "Block position" begin
            for pos in CartesianIndex(1, 1):CartesianIndex(grid.grid_size)
                blk = Armon.block_at(grid, pos)
                @test blk.pos == pos
                @test blk isa Armon.LocalTaskBlock
                @test Armon.block_size_at(grid, pos) == Armon.real_block_size(blk)
            end

            for (_, region) in Armon.RemoteBlockRegions(grid.grid_size), pos in region
                blk = Armon.block_at(grid, pos)
                @test blk.pos == pos
                @test blk isa Armon.RemoteTaskBlock
            end
        end
    end

    @testset "Errors" begin
        @test_throws "block size (5, 5) is too small" begin
            ref_params = get_reference_params(:Sod, Float64; N=(100, 100), block_size=(5, 5), nghost=4)
            Armon.BlockGrid(ref_params)
        end

        @test_throws "block size (20, 10) is too small" begin
            ref_params = get_reference_params(:Sod, Float64; N=(100, 100), block_size=(20, 10), nghost=4)
            Armon.BlockGrid(ref_params)
        end
    end
end


@testset "Block size" begin
    @testset "$bsize" for bsize in (
            Armon.StaticBSize((64, 64), 5),
            Armon.StaticBSize((37, 39), 5),
            Armon.DynamicBSize((64, 37), 5),
            Armon.DynamicBSize((37, 39), 1),
            Armon.DynamicBSize((37, 39), 0))

        @test Armon.ghosts(bsize) in (5, 1, 0)
        @test Armon.real_block_size(bsize) == Armon.block_size(bsize) .- 2*Armon.ghosts(bsize)
        @test ndims(bsize) == 2

        @testset "Full domain" begin
            g = Armon.ghosts(bsize)
            all_cells = Armon.block_domain_range(bsize, (-g, -g), (g, g))
            @test size(all_cells) == Armon.block_size(bsize)

            pos_ok = 0
            lin_pos_ok = 0
            ghost_ok = 0
            for (ij, j) in enumerate(all_cells.col), (ii, i) in enumerate(all_cells.row .+ (j - 1))
                I = (ii - g, ij - g)
                pos_ok     += Armon.position(bsize, i) == I
                lin_pos_ok += Armon.lin_position(bsize, I) == i
                ghost_ok   += Armon.is_ghost(bsize, i) == (any(I .â‰¤ 0) || any(I .> Armon.real_block_size(bsize)))
            end
            @test pos_ok     == length(all_cells)
            @test lin_pos_ok == length(all_cells)
            @test ghost_ok   == length(all_cells)
        end

        @testset "Real domain" begin
            real_cells = Armon.block_domain_range(bsize, (0, 0), (0, 0))            
            @test size(real_cells) == Armon.real_block_size(bsize)

            pos_ok = 0
            lin_pos_ok = 0
            ghost_ok = 0
            for (ij, j) in enumerate(real_cells.col), (ii, i) in enumerate(real_cells.row .+ (j - 1))
                I = (ii, ij)
                pos_ok     += Armon.position(bsize, i) == I
                lin_pos_ok += Armon.lin_position(bsize, I) == i
                ghost_ok   += !Armon.is_ghost(bsize, i)
            end
            @test pos_ok     == length(real_cells)
            @test lin_pos_ok == length(real_cells)
            @test ghost_ok   == length(real_cells)
        end

        @testset "$side domain" for side in instances(Armon.Side.T)
            border = Armon.border_domain(bsize, side)
            expected_size = Armon.real_size_along(bsize, Armon.next_axis(Armon.axis_of(side)))
            @test length(border) == expected_size
            if Armon.axis_of(side) == Armon.Axis.X
                @test size(border) == (1, expected_size)
            else
                @test size(border) == (expected_size, 1)
            end

            ghost_border = Armon.ghost_domain(bsize, side; single_strip=false)
            @test length(ghost_border) == expected_size * Armon.ghosts(bsize)
            if Armon.axis_of(side) == Armon.Axis.X
                @test size(ghost_border) == (Armon.ghosts(bsize), expected_size)
            else
                @test size(ghost_border) == (expected_size, Armon.ghosts(bsize))
            end
        end

        @test Armon.stride_along(bsize, Armon.Axis.X) == abs(Armon.lin_position(bsize, (1, 1)) - Armon.lin_position(bsize, (2, 1)))
        @test Armon.stride_along(bsize, Armon.Axis.Y) == abs(Armon.lin_position(bsize, (1, 1)) - Armon.lin_position(bsize, (1, 2)))
        @test Armon.size_along(bsize, Armon.Axis.X) == Armon.size_along(bsize, Armon.Side.Left) == Armon.size_along(bsize, Armon.Side.Right) == Armon.block_size(bsize)[1]
        @test Armon.size_along(bsize, Armon.Axis.Y) == Armon.size_along(bsize, Armon.Side.Bottom) == Armon.size_along(bsize, Armon.Side.Top) == Armon.block_size(bsize)[2]
    end
end


@testset "Row iterator" begin
    @testset "$(join(N, 'Ã—')) - $(join(B, 'Ã—')) - $g" for (g, N, B) in (
        (5, (100, 100), (32, 32)),
        (5, ( 47, 100), (17, 37)),
        (4, ( 96,  96), (32, 32)),  # No edge blocks
        (4, ( 16,  16), (32, 32)),  # Only edge blocks
        (4, (100,  50), (64, 64)),  # Only edge blocks, multiple along X
        (4, ( 50, 100), (64, 64)),  # Only edge blocks, multiple along Y
        (4, (107,  57), (64, 64)),  # Only edge blocks, multiple along X, with a fused block at the end
        (4, ( 53,  56), (64, 64)),  # One edge block, but one of the side fits the block size exactly
        (4, ( 53, 112), (64, 64)),  # Two edge blocks, but one of the side fits the block size exactly
        (3, ( 16,  33), ( 0,  0)),  # No blocking, only edge blocks
        (4, (100, 100), (57, 57)),  # Edge blocks bigger than static blocks
        (0, (100, 100), (32, 32)),  # 0 ghosts
        (4, ( 24,   8), (20, 12)),  # Example in doc
    )
        params = ArmonParameters(;
            test=:DebugIndexes, nghost=5, N, block_size=B,
            use_MPI=false, data_type=Float64
        )
        params.nghost = g  # We must do this after the constructor to avoid checks with the schemes
        Armon.compute_steps_ranges(params)
        grid = Armon.BlockGrid(params)
        Armon.init_test(params, grid)

        # Iterate through all real cells of all blocks
        i = 1
        fail_pos = nothing
        for (blk, row_idx, row_range) in Armon.BlockRowIterator(grid)
            expected_length = Armon.real_size_along(blk.size, Armon.Axis.X)
            blk_data = Armon.block_host_data(blk)
            if length(row_range) == expected_length && all((i:i+expected_length-1) .== blk_data.Ï[row_range])
                i += expected_length
            else
                fail_pos = (blk.pos, row_idx, row_range, blk_data.Ï[row_range])
                break
            end
        end
        @test fail_pos === nothing
        @test i - 1 == prod(N)

        # All blocks with only the global domain ghosts
        total = 0
        fail_pos = nothing
        for (blk, row_idx, row_range) in Armon.BlockRowIterator(grid; global_ghosts=true)
            blk_data = Armon.block_host_data(blk)
            if !checkbounds(Bool, blk_data.Ï, row_range)
                fail_pos = (blk.pos, row_idx, row_range)
                break
            end
            total += length(row_range)
        end
        @test fail_pos === nothing
        @test total == prod(N .+ 2g)

        # All blocks with all ghosts
        total = 0
        fail_pos = nothing
        for (blk, row_idx, row_range) in Armon.BlockRowIterator(grid; all_ghosts=true)
            blk_data = Armon.block_host_data(blk)
            if !checkbounds(Bool, blk_data.Ï, row_range)
                fail_pos = (blk.pos, row_idx, row_range)
                break
            end
            total += length(row_range)
        end
        total_cells = sum(prod.(Armon.block_size.(Armon.all_blocks(grid))))
        @test fail_pos === nothing
        @test total == total_cells

        # Using cell sub domain
        total = 0
        fail_pos = nothing
        for row in 1:N[2]
            row_start = CartesianIndex(1, row)
            row_end = CartesianIndex(N[1], row)
            for (blk, row_idx, row_range) in Armon.BlockRowIterator(grid, (row_start, row_end))
                blk_data = Armon.block_host_data(blk)
                if !checkbounds(Bool, blk_data.Ï, row_range)
                    fail_pos = (blk.pos, row_idx, row_range)
                    break
                end
                total += length(row_range)
            end
        end
        @test fail_pos === nothing
        @test total == prod(N)

        # Using cell sub domain with ghosts
        total = 0
        fail_pos = nothing
        for row in 1-g:N[2]+g
            row_start = CartesianIndex(1, row)
            row_end = CartesianIndex(N[1], row)
            for (blk, row_idx, row_range) in Armon.BlockRowIterator(grid, (row_start, row_end); global_ghosts=true)
                blk_data = Armon.block_host_data(blk)
                if !checkbounds(Bool, blk_data.Ï, row_range)
                    fail_pos = (blk.pos, row_idx, row_range)
                    break
                end
                total += length(row_range)
            end
        end
        @test fail_pos === nothing
        @test total == prod(N .+ 2g)
    end
end


@testset "Workload Distribution" begin
    function check_distribution(params, parts; kwargs...)
        grid_size, _, _ = Armon.grid_dimensions(params)
        distrib = Armon.thread_workload_distribution(params; threads=parts, kwargs...)

        expected_workload     = prod(grid_size) Ã· parts
        expected_remainder    = prod(grid_size) - expected_workload * parts
        expected_max_workload = expected_workload + (expected_remainder > 0)

        distrib_count = length.(distrib)
        @test sum(distrib_count) == prod(grid_size)
        @test maximum(distrib_count) â‰¤ expected_max_workload
        @test sum(abs.(distrib_count .- expected_workload)) == expected_remainder

        blk_grid = Armon.block_grid_from_workload(grid_size, distrib)
        @test count(==(0), blk_grid) == 0  # All blocks are assigned to a thread
    end

    @testset "Simple" begin
        @testset "$(join(N, 'Ã—')) - $(join(block_size, 'Ã—')) - $nghost" for (N, block_size, nghost) in (
                ((100, 100), (16, 16), 4),
                ((240, 240), (64, 32), 4),
                ((240, 240), (32, 17), 4),
            )
            ref_params = get_reference_params(:Sod, Float64; nghost, N, block_size, workload_distribution=:simple)
            @testset "parts=$parts" for parts in (1, 4, 7, 59, 64)
                check_distribution(ref_params, parts)
            end
        end
    end

    @testset "Scotch" begin
        # Fixed seed for test reproductibility
        Armon.Scotch.random_seed(12345)
        Armon.Scotch.random_reset()

        @testset "$(join(N, 'Ã—')) - $(join(block_size, 'Ã—')) - $nghost" for (N, block_size, nghost) in (
                ((100, 100), (16, 16), 4),
                ((240, 240), (64, 32), 4),
                ((240, 240), (32, 17), 4),
            )
            ref_params = get_reference_params(:Sod, Float64; nghost, N, block_size, workload_distribution=:scotch)
            @testset "parts=$parts" for parts in (1, 4, 7, 59, 64)
                # retry 10 times to ensure that we hit the optimal partitioning at least once
                check_distribution(ref_params, parts)
            end
        end
    end
end


@testset "NUMA" begin
    if NUMA.numa_available()
        pinthreads(:cores)
        tid_map = Armon.tid_to_numa_node_map()
    else
        tid_map = Int[]
    end


    function check_for_page_sharing(all_the_pages; disp_first=0)
        # Check if any arrays are sharing a memory page.
        # This would cause issues if e.g. the array are in different blocks, themselves in different
        # NUMA groups: then it would be impossible to efficently place all pages.
        # The check is exhaustive so it runs in ð“ž(NÂ²).
        sharing_count = 0
        for (i, (numa_id, page_range)) in enumerate(all_the_pages),
                (other_numa_id, other_page_range) in all_the_pages[i+1:end]
            if numa_id != other_numa_id && !isdisjoint(page_range, other_page_range)
                sharing_count += 1
                if disp_first > 0
                    disp_first -= 1
                    println("Those two page ranges are both on the NUMA node $numa_id and $other_numa_id: \n\
                              - $page_range\n\
                              - $other_page_range")
                end
            end
        end
        return sharing_count
    end


    function get_all_grid_pages(grid)
        # All `(expected_numa_id, page_range)` pairs for all arrays of every block of the `grid`
        all_pages = Vector{Tuple{Int, StepRange{Ptr{Float64}, Int}}}()
        for (tid, blks_pos) in enumerate(grid.threads_workload), blk_pos in blks_pos
            blk = Armon.block_at(grid, blk_pos)
            numa_id = tid_map[tid]
            for var in Armon.block_vars(blk)
                push!(all_pages, (numa_id, Armon.array_pages(var)))
            end
        end
        return all_pages
    end


    function numa_blk_grid(grid)
        # Returns a NxM grid of which NUMA node is set to the first page of the first variable of all blocks
        numa_blks = Array{Int}(undef, grid.grid_size)
        for blk_pos in eachindex(Base.IndexCartesian(), numa_blks)
            blk = Armon.block_at(grid, blk_pos)
            var = Armon.get_vars(blk, (:x,)) |> only
            idx_mid = (lastindex(var) + firstindex(var)) Ã· 2
            numa_node = NUMA.which_numa_node(var, idx_mid)
            numa_blks[blk_pos] = numa_node
        end
        return numa_blks
    end


    function check_block_numa(blk, test_domain, expected_tid)
        vars = Armon.block_vars()
        blk_range = Armon.block_domain_range(blk.size, test_domain)
        target_numa = tid_map[expected_tid]
        err_count = 0
        first_err_var = nothing
        for (var_name, var) in zip(vars, Armon.get_vars(blk, vars))
            # Only check the first and last index of the array
            first_numa = NUMA.which_numa_node(var, first(blk_range))
            last_numa  = NUMA.which_numa_node(var, last(blk_range))
            if !(first_numa == last_numa == target_numa)
                println("at block $(Tuple(blk.pos)) for var $var_name \
                         expected $target_numa for tid $expected_tid, got:\n\
                          - first_numa = $first_numa (idx=$(first(blk_range)))\n\
                          - last_numa  = $last_numa (idx=$(last(blk_range)))\n")
                err_count == 0 && (first_err_var = var_name)
                err_count += 1
            end
        end
        return err_count, first_err_var
    end


    function check_grid_numa(grid, test_domain)
        err_count = 0
        first_err_blk_pos = nothing
        first_err_var = nothing
        for (tid, blks_pos) in enumerate(grid.threads_workload), blk_pos in blks_pos
            page_err_count, fail_var_name = if Armon.in_grid(blk_pos, grid.static_sized_grid)
                blk = grid.blocks[Armon.block_idx(grid, blk_pos)]
                check_block_numa(blk, test_domain, tid)
            else
                blk = grid.edge_blocks[Armon.edge_block_idx(grid, blk_pos)]
                check_block_numa(blk, test_domain, tid)
            end

            if page_err_count > 0
                if err_count == 0
                    first_err_blk_pos = blk_pos
                    first_err_var = fail_var_name
                end
                err_count += page_err_count
            end
        end
        return err_count, first_err_blk_pos, first_err_var
    end


    if NUMA.numa_available()
        @testset "move_pages" begin
            v = Vector{Int64}(undef, 1_000_000)
            v_pages = Armon.array_pages(v)
            Armon.touch_pages(v_pages)
            @test Armon.move_pages(v_pages, 1) === nothing
        end

        n = round(Int, sqrt(10000 * Threads.nthreads()))  # 100x100 per core
        N = (n, n)
        params = get_reference_params(:Sod_circ, Float64;
            N, block_size=(64, 64), maxcycle=5,
            use_threading=true, use_cache_blocking=true, async_cycle=true,
            workload_distribution=:scotch, numa_aware=true, lock_memory=true
        )

        grid = Armon.BlockGrid(params)
        test_domain = first(params.steps_ranges).full_domain

        # Page positions should be properly enforced after initialization
        Armon.init_test(params, grid)
        @test check_grid_numa(grid, test_domain) == (0, nothing, nothing)
        @test check_for_page_sharing(get_all_grid_pages(grid)) == 0

        # Pages shouldn't move after some solver iterations
        Armon.time_loop(params, grid)
        @test check_grid_numa(grid, test_domain) == (0, nothing, nothing)
    else
        @warn "NUMA is unavailable"
        @test false skip=true
    end
end

end
